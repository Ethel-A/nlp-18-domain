{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re;\n",
    "import math;\n",
    "\n",
    "categories = []\n",
    "normal = []\n",
    "counts = []\n",
    "vocab = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This function calculates and returns the list of sentences labeled positive and negative respectively'''\n",
    "def categorize(filename):\n",
    "    with open(filename) as train_data:\n",
    "        train_list = train_data.readlines();\n",
    "        positive = [];\n",
    "        negative = [];\n",
    "        #try:\n",
    "        for item in train_list:\n",
    "            feat = item.strip('\\n');\n",
    "            if(feat[-1] == '0'): #The statement is a negative\n",
    "                negative.append(feat[:-2]);\n",
    "            elif(feat[-1] == '1'):#The statement is a positive\n",
    "                positive.append(feat[:-2]);\n",
    "            else:\n",
    "                print( feat + \": \" + feat[-1] + 'Error in data');\n",
    "                return;\n",
    "        return(positive, negative)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This function normalizes (takes out punctuations and converts into lowercase all the words in the positive and negative class respectively'''\n",
    "def normalize(positive,negative):\n",
    "    pos = positive;\n",
    "    neg = negative;\n",
    "    pos_words = [];\n",
    "    neg_words = [];\n",
    "    for sentence in pos:\n",
    "        checked = re.sub(r'[^\\w\\s]','',sentence) # removing all punctuations except hyphens\n",
    "        checked = checked.lower();\n",
    "        x = checked.split(' ');\n",
    "        for word in x:\n",
    "            pos_words.append(word);\n",
    "    for sentence in neg:\n",
    "        checked = re.sub(r'[^\\w\\s]','',sentence) # removing all punctuations except hyphens\n",
    "        checked = checked.lower();\n",
    "        y = checked.split(' ');\n",
    "        for word in y:\n",
    "            neg_words.append(word);\n",
    "    return pos_words,neg_words\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This function creates and returns a dictionary with the words/features as keys and their frequency as values for each class'''\n",
    "def count(pos_words, neg_words):\n",
    "    pos_dict = {};\n",
    "    neg_dict = {};\n",
    "    pos = pos_words;\n",
    "    neg = neg_words;\n",
    "    for word in pos:\n",
    "        if word not in pos_dict:\n",
    "            pos_dict[word] = 1;\n",
    "        else:\n",
    "            pos_dict[word]+=1\n",
    "\n",
    "    for word in neg:\n",
    "        if word not in neg_dict:\n",
    "            neg_dict[word] = 1;\n",
    "        else:\n",
    "            neg_dict[word]+=1;\n",
    "\n",
    "    return pos_dict, neg_dict;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''this function combines and returns a set (unique) of all the words in both the positive and negative class'''\n",
    "def vocabularize(pos_dict, neg_dict):\n",
    "    pos_count = pos_dict;\n",
    "    neg_count = neg_dict;\n",
    "    vocabulary = set();\n",
    "    for word in pos_count:\n",
    "        vocabulary.add(word);\n",
    "    for word in neg_count:\n",
    "        vocabulary.add(word);\n",
    "    return vocabulary;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''this function normalizes (no punctuation and all lowercase) the test input before testing'''\n",
    "def test_normalizer(filename):\n",
    "    with open(filename) as test_data:\n",
    "        test_list = test_data.readlines();\n",
    "        stripped_list = [];\n",
    "        for item in test_list:\n",
    "            splitz = ' '.join(item.split());\n",
    "            stripped_list.append(splitz); #for working on normal datasets (unlabelled)\n",
    "            #stripped_list.append(splitz[:-2]); #for working on labeled datasets\n",
    "        #return stripped_list;\n",
    "        normalized = [];\n",
    "        for sentence in stripped_list:\n",
    "            checked = re.sub(r'[^\\w\\s]','',sentence) # removing all punctuations except hyphens\n",
    "            checked = checked.lower();\n",
    "            normalized.append(checked);\n",
    "        return normalized;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''The function below initializes the values for the global variables. it is the only function that modifies the variables.\n",
    "all other function just read the variables'''\n",
    "def initialize(filename):\n",
    "    global categories\n",
    "    global normal\n",
    "    global counts\n",
    "    global vocab\n",
    "    categories = categorize(filename);#returns 2 lists- positive and negative sentences\n",
    "    normal = normalize(categories[0], categories[1]);   #returns normalized lists of words\n",
    "    counts = count(normal[0], normal[1]); # returns positive and negative dictionaries\n",
    "    vocab = vocabularize(counts[0], counts[1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This function calculates and returns the prior probability of both the positive and negative class'''    \n",
    "def prior():\n",
    "    pos_total = len(categories[0]) # length of positve sentences list\n",
    "    neg_total = len(categories[1]) # length of negative sentences list\n",
    "    pos_prob = pos_total/(pos_total + neg_total) # probability of the positive class\n",
    "    neg_prob = neg_total/(pos_total + neg_total) # probability of the negative class\n",
    "    return pos_prob, neg_prob;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This function calculates and returns the denominator of the likelihood probability of both the positive and negative class'''\n",
    "def like_deno():\n",
    "    vocab_len = len(vocab);\n",
    "    #print(\"Vocab Length: '\" + str(vocab_len));\n",
    "    pos_len = 0;\n",
    "    neg_len = 0;\n",
    "    pos_freq = list(counts[0].values())\n",
    "    neg_freq = list(counts[1].values())\n",
    "    for freq in pos_freq:\n",
    "        pos_len += freq\n",
    "    for freq in neg_freq:\n",
    "        neg_len += freq;\n",
    "    #print(\"Positive length: \" + str(pos_len))\n",
    "    #print(\"Negative lenght: \" + str(neg_len))\n",
    "    pos_deno = vocab_len + pos_len\n",
    "    neg_deno = vocab_len + neg_len\n",
    "    return pos_deno, neg_deno;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''The function below calculates a list of probabilities of each sentence given the positive class. takes in a normlaized test'''\n",
    "def pos_tester(test):\n",
    "    #test = test_normalizer(filename);\n",
    "    priors = prior();\n",
    "    pos_prior = priors[0];\n",
    "    denos = like_deno();\n",
    "    pos_deno = denos[0];\n",
    "    pos_count = counts[0];\n",
    "    pos_probs = [];\n",
    "    for doc in test:\n",
    "        cumm = 1;\n",
    "        test = doc.split(' ');\n",
    "        for word in test:\n",
    "            if (word in vocab and word in pos_count) :\n",
    "                freq = pos_count[word] + 1\n",
    "            elif(word in vocab):\n",
    "                freq = 1;\n",
    "            else:\n",
    "                continue;\n",
    "            cumm *= (freq/pos_deno);\n",
    "        cumm *= pos_prior;\n",
    "        pos_probs.append(cumm);\n",
    "        #print(cumm);\n",
    "    return pos_probs;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''The function below calculates a list of probabilities of each sentence given the positive class. takes in a normlaized test'''\n",
    "def neg_tester(test):\n",
    "    #test = test_normalizer(test);\n",
    "    priors = prior();\n",
    "    neg_prior = priors[1];\n",
    "    denos = like_deno();\n",
    "    neg_deno = denos[1]\n",
    "    neg_count = counts[1];\n",
    "    neg_probs = [];\n",
    "    for doc in test:\n",
    "        cumm = 1;\n",
    "        test = doc.split(' ');\n",
    "        for word in test:\n",
    "            if (word in vocab and word in neg_count) :\n",
    "                freq = neg_count[word] + 1\n",
    "            elif(word in vocab):\n",
    "                freq = 1;\n",
    "            else:\n",
    "                continue;\n",
    "            cumm *= (freq/neg_deno);\n",
    "        cumm *= neg_prior;\n",
    "        neg_probs.append(cumm);\n",
    "        #print(cumm);\n",
    "    return neg_probs;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''The function below calculates and returns the estimated class of the various sentences in the test file'''\n",
    "def tester(filename):\n",
    "    test = test_normalizer(filename);\n",
    "    positives = pos_tester(test)\n",
    "    negatives = neg_tester(test)\n",
    "    results_file = open('results_file.txt','w+')\n",
    "    results = []\n",
    "    for i in range(len(positives)):\n",
    "        if positives[i] > negatives[i]:\n",
    "            results_file.write('1' + '\\n');\n",
    "            results.append('Positive')\n",
    "        elif positives[i] < negatives[i]:\n",
    "            results.append('Negative')\n",
    "            results_file.write('0' + '\\n');\n",
    "        else:\n",
    "            results.append('neutral');\n",
    "    results_file.close();\n",
    "    return results;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Master function'''\n",
    "def boss(trainfile, testfile):\n",
    "    initialize(trainfile);\n",
    "    return tester(testfile);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter file name: yelp.txt\n"
     ]
    }
   ],
   "source": [
    "name = input(\"Enter file name: \")\n",
    "boss('bigTrain.txt',name);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
